{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-08-25T17:24:43.816762Z","iopub.status.busy":"2023-08-25T17:24:43.815853Z","iopub.status.idle":"2023-08-25T17:24:43.834829Z","shell.execute_reply":"2023-08-25T17:24:43.832653Z","shell.execute_reply.started":"2023-08-25T17:24:43.816676Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["./input\\intents.json\n","./input\\Testing.csv\n","./input\\Training.csv\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('./input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-08-25T17:24:43.847109Z","iopub.status.busy":"2023-08-25T17:24:43.846181Z","iopub.status.idle":"2023-08-25T17:24:48.147179Z","shell.execute_reply":"2023-08-25T17:24:48.145635Z","shell.execute_reply.started":"2023-08-25T17:24:43.847022Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     C:\\Users\\Akshay\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["import numpy as np\n","import random\n","import json\n","\n","import torch\n","import torch.nn as nn\n","import nltk\n","nltk.download('punkt')\n","\n","from torch.utils.data import Dataset, DataLoader\n","\n","import numpy as np\n","from nltk.stem.porter import PorterStemmer\n","stemmer = PorterStemmer()\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-08-25T17:24:48.149772Z","iopub.status.busy":"2023-08-25T17:24:48.149009Z","iopub.status.idle":"2023-08-25T17:24:48.163050Z","shell.execute_reply":"2023-08-25T17:24:48.161584Z","shell.execute_reply.started":"2023-08-25T17:24:48.149715Z"},"trusted":true},"outputs":[],"source":["# ANN Model\n","\n","class NeuralNet(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_classes):\n","        super(NeuralNet, self).__init__()\n","        self.l1 = nn.Linear(input_size, hidden_size) \n","        self.l2 = nn.Linear(hidden_size, hidden_size) \n","        self.l3 = nn.Linear(hidden_size, num_classes)\n","        self.relu = nn.ReLU()\n","    \n","    def forward(self, x):\n","        out = self.l1(x)\n","        out = self.relu(out)\n","        out = self.l2(out)\n","        out = self.relu(out)\n","        out = self.l3(out)\n","        # no activation and no softmax at the end\n","        return out"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-08-25T17:24:48.166598Z","iopub.status.busy":"2023-08-25T17:24:48.166193Z","iopub.status.idle":"2023-08-25T17:24:48.187062Z","shell.execute_reply":"2023-08-25T17:24:48.185970Z","shell.execute_reply.started":"2023-08-25T17:24:48.166559Z"},"trusted":true},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/mental-health-conversational-data/intents.json'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39m/kaggle/input/mental-health-conversational-data/intents.json\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m      2\u001b[0m     intents \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n","File \u001b[1;32mc:\\Program Files\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/mental-health-conversational-data/intents.json'"]}],"source":["with open('../Hackathon/input/intents.json', 'r') as f:\n","    intents = json.load(f)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-25T17:24:48.189121Z","iopub.status.busy":"2023-08-25T17:24:48.188769Z","iopub.status.idle":"2023-08-25T17:24:48.200037Z","shell.execute_reply":"2023-08-25T17:24:48.198641Z","shell.execute_reply.started":"2023-08-25T17:24:48.189085Z"},"trusted":true},"outputs":[],"source":["\n","\n","def tokenize(sentence):\n","    \"\"\"\n","    split sentence into array of words/tokens\n","    a token can be a word or punctuation character, or number\n","    \"\"\"\n","    return nltk.word_tokenize(sentence)\n","\n","\n","def stem(word):\n","    \"\"\"\n","    stemming = find the root form of the word\n","    examples:\n","    words = [\"organize\", \"organizes\", \"organizing\"]\n","    words = [stem(w) for w in words]\n","    -> [\"organ\", \"organ\", \"organ\"]\n","    \"\"\"\n","    return stemmer.stem(word.lower())\n","\n","\n","def bag_of_words(tokenized_sentence, words):\n","    \"\"\"\n","    return bag of words array:\n","    1 for each known word that exists in the sentence, 0 otherwise\n","    example:\n","    sentence = [\"hello\", \"how\", \"are\", \"you\"]\n","    words = [\"hi\", \"hello\", \"I\", \"you\", \"bye\", \"thank\", \"cool\"]\n","    bog   = [  0 ,    1 ,    0 ,   1 ,    0 ,    0 ,      0]\n","    \"\"\"\n","    # stem each word\n","    sentence_words = [stem(word) for word in tokenized_sentence]\n","    # initialize bag with 0 for each word\n","    bag = np.zeros(len(words), dtype=np.float32)\n","    for idx, w in enumerate(words):\n","        if w in sentence_words: \n","            bag[idx] = 1\n","\n","    return bag"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-25T17:24:48.201874Z","iopub.status.busy":"2023-08-25T17:24:48.201493Z","iopub.status.idle":"2023-08-25T17:24:48.298937Z","shell.execute_reply":"2023-08-25T17:24:48.297589Z","shell.execute_reply.started":"2023-08-25T17:24:48.201835Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["232 patterns\n","80 tags: ['about', 'afternoon', 'anxious', 'ask', 'casual', 'creation', 'death', 'default', 'depressed', 'done', 'evening', 'fact-1', 'fact-10', 'fact-11', 'fact-12', 'fact-13', 'fact-14', 'fact-15', 'fact-16', 'fact-17', 'fact-18', 'fact-19', 'fact-2', 'fact-20', 'fact-21', 'fact-22', 'fact-23', 'fact-24', 'fact-25', 'fact-26', 'fact-27', 'fact-28', 'fact-29', 'fact-3', 'fact-30', 'fact-31', 'fact-32', 'fact-5', 'fact-6', 'fact-7', 'fact-8', 'fact-9', 'friends', 'goodbye', 'greeting', 'happy', 'hate-me', 'hate-you', 'help', 'jokes', 'learn-mental-health', 'learn-more', 'location', 'meditation', 'mental-health-fact', 'morning', 'name', 'neutral-response', 'night', 'no-approach', 'no-response', 'not-talking', 'pandora-useful', 'problem', 'repeat', 'sad', 'scared', 'skill', 'sleep', 'something-else', 'stressed', 'stupid', 'suicide', 'thanks', 'understand', 'user-advice', 'user-agree', 'user-meditation', 'worthless', 'wrong']\n","280 unique stemmed words: [\"'ll\", \"'m\", \"'re\", \"'s\", \"'ve\", ',', 'a', 'about', 'absolut', 'advic', 'affect', 'afternoon', 'again', 'all', 'alot', 'alreadi', 'am', 'and', 'ani', 'anoth', 'answer', 'anxieti', 'anxiou', 'anymor', 'anyon', 'anyth', 'appear', 'approach', 'are', 'ask', 'au', 'avail', 'aw', 'away', 'be', 'becaus', 'becom', 'befor', 'better', 'between', 'bonjour', 'boyfriend', 'break', 'bring', 'brother', 'burn', 'by', 'bye', 'ca', 'call', 'can', 'caus', 'cheer', 'child', 'commit', 'connect', 'continu', 'control', 'could', 'crazi', 'creat', 'cure', 'dad', 'day', 'defin', 'depress', 'deserv', 'did', 'die', 'differ', 'disord', 'do', 'doe', 'down', 'dumb', 'els', 'empti', 'enough', 'even', 'exam', 'fact', 'famili', 'fare', 'feel', 'few', 'financi', 'find', 'fine', 'focu', 'for', 'friend', 'from', 'get', 'girlfriend', 'give', 'go', 'good', 'goodby', 'great', 'group', 'guess', 'guten', 'had', 'hand', 'happi', 'hate', 'have', 'health', 'hello', 'help', 'hey', 'hi', 'hmmm', 'hola', 'how', 'howdi', 'i', 'if', 'ill', 'import', 'in', 'insominia', 'insomnia', 'interest', 'involv', 'is', 'it', 'joke', 'just', 'k', 'kill', 'know', 'konnichiwa', 'last', 'later', 'learn', 'let', 'like', 'live', 'locat', 'lone', 'made', 'maintain', 'make', 'me', 'mean', 'medic', 'medit', 'mental', 'mention', 'mom', 'money', 'more', 'morn', 'much', 'my', 'myself', \"n't\", 'name', 'need', 'new', 'nice', 'night', 'no', 'nobodi', 'not', 'noth', 'now', 'of', 'oh', 'ok', 'okay', 'ola', 'on', 'one', 'open', 'option', 'or', 'out', 'pass', 'past', 'peopl', 'pleas', 'possibl', 'practic', 'prepar', 'prevent', 'probabl', 'problem', 'profession', 'proper', 'realli', 'recov', 'relationship', 'repeat', 'respons', 'revoir', 'right', 'robot', 'sad', 'said', 'say', 'sayonara', 'scare', 'see', 'seem', 'sens', 'should', 'shut', 'sign', 'sister', 'sleep', 'slept', 'so', 'social', 'some', 'someon', 'someth', 'sound', 'start', 'stay', 'still', 'stress', 'stuck', 'stupid', 'suffer', 'suicid', 'support', 'sure', 'symptom', 'tag', 'take', 'talk', 'tell', 'than', 'thank', 'that', 'the', 'thee', 'then', 'therapi', 'therapist', 'there', 'thi', 'think', 'thought', 'through', 'to', 'today', 'told', 'treatment', 'trust', 'type', 'understand', 'unwel', 'up', 'use', 'useless', 'veri', 'want', 'warn', 'way', 'we', 'well', 'were', 'what', 'whatev', 'where', 'whi', 'who', 'with', 'worri', 'worthless', 'would', 'wrong', 'ye', 'yeah', 'you', 'your', 'yourself']\n"]}],"source":["all_words = []\n","tags = []\n","xy = []\n","# loop through each sentence in our intents patterns\n","for intent in intents['intents']:\n","    tag = intent['tag']\n","    # add to tag list\n","    tags.append(tag)\n","    for pattern in intent['patterns']:\n","        # tokenize each word in the sentence\n","        w = tokenize(pattern)\n","        # add to our words list\n","        all_words.extend(w)\n","        # add to xy pair\n","        xy.append((w, tag))\n","\n","# stem and lower each word\n","ignore_words = ['?', '.', '!']\n","all_words = [stem(w) for w in all_words if w not in ignore_words]\n","# remove duplicates and sort\n","all_words = sorted(set(all_words))\n","tags = sorted(set(tags))\n","\n","print(len(xy), \"patterns\")\n","print(len(tags), \"tags:\", tags)\n","print(len(all_words), \"unique stemmed words:\", all_words)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-25T17:24:48.301273Z","iopub.status.busy":"2023-08-25T17:24:48.300897Z","iopub.status.idle":"2023-08-25T17:24:48.357683Z","shell.execute_reply":"2023-08-25T17:24:48.356014Z","shell.execute_reply.started":"2023-08-25T17:24:48.301235Z"},"trusted":true},"outputs":[],"source":["# create training data\n","X_train = []\n","y_train = []\n","for (pattern_sentence, tag) in xy:\n","    # X: bag of words for each pattern_sentence\n","    bag = bag_of_words(pattern_sentence, all_words)\n","    X_train.append(bag)\n","    # y: PyTorch CrossEntropyLoss needs only class labels, not one-hot\n","    label = tags.index(tag)\n","    y_train.append(label)\n","\n","X_train = np.array(X_train)\n","y_train = np.array(y_train)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-25T17:24:48.359520Z","iopub.status.busy":"2023-08-25T17:24:48.359113Z","iopub.status.idle":"2023-08-25T17:24:48.372612Z","shell.execute_reply":"2023-08-25T17:24:48.371251Z","shell.execute_reply.started":"2023-08-25T17:24:48.359473Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["280 80\n"]}],"source":["# Hyper-parameters \n","num_epochs = 1000\n","batch_size = 8\n","learning_rate = 0.001\n","input_size = len(X_train[0])\n","hidden_size = 8\n","output_size = len(tags)\n","print(input_size, output_size)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-25T17:24:48.374366Z","iopub.status.busy":"2023-08-25T17:24:48.373969Z","iopub.status.idle":"2023-08-25T17:24:48.385693Z","shell.execute_reply":"2023-08-25T17:24:48.384391Z","shell.execute_reply.started":"2023-08-25T17:24:48.374329Z"},"trusted":true},"outputs":[],"source":["class ChatDataset(Dataset):\n","\n","    def __init__(self):\n","        self.n_samples = len(X_train)\n","        self.x_data = X_train\n","        self.y_data = y_train\n","\n","    # support indexing such that dataset[i] can be used to get i-th sample\n","    def __getitem__(self, index):\n","        return self.x_data[index], self.y_data[index]\n","\n","    # we can call len(dataset) to return the size\n","    def __len__(self):\n","        return self.n_samples\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-25T17:24:48.390454Z","iopub.status.busy":"2023-08-25T17:24:48.389732Z","iopub.status.idle":"2023-08-25T17:24:48.445313Z","shell.execute_reply":"2023-08-25T17:24:48.443778Z","shell.execute_reply.started":"2023-08-25T17:24:48.390409Z"},"trusted":true},"outputs":[],"source":["dataset = ChatDataset()\n","train_loader = DataLoader(dataset=dataset,\n","                          batch_size=batch_size,\n","                          shuffle=True,\n","                          num_workers=0)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","model = NeuralNet(input_size, hidden_size, output_size).to(device)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-25T17:24:48.447293Z","iopub.status.busy":"2023-08-25T17:24:48.446840Z","iopub.status.idle":"2023-08-25T17:25:21.937684Z","shell.execute_reply":"2023-08-25T17:25:21.936317Z","shell.execute_reply.started":"2023-08-25T17:24:48.447239Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [100/1000], Loss: 0.2861\n","Epoch [200/1000], Loss: 0.0437\n","Epoch [300/1000], Loss: 0.0040\n","Epoch [400/1000], Loss: 0.0003\n","Epoch [500/1000], Loss: 0.0001\n","Epoch [600/1000], Loss: 0.0000\n","Epoch [700/1000], Loss: 0.0000\n","Epoch [800/1000], Loss: 0.0000\n","Epoch [900/1000], Loss: 0.0000\n","Epoch [1000/1000], Loss: 0.0000\n","final loss: 0.0000\n"]}],"source":["# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# Train the model\n","for epoch in range(num_epochs):\n","    for (words, labels) in train_loader:\n","        words = words.to(device)\n","        labels = labels.to(dtype=torch.long).to(device)\n","        \n","        # Forward pass\n","        outputs = model(words)\n","        # if y would be one-hot, we must apply\n","        # labels = torch.max(labels, 1)[1]\n","        loss = criterion(outputs, labels)\n","        \n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","    if (epoch+1) % 100 == 0:\n","        print (f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n","\n","\n","print(f'final loss: {loss.item():.4f}')\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-25T17:25:21.939518Z","iopub.status.busy":"2023-08-25T17:25:21.939120Z","iopub.status.idle":"2023-08-25T17:25:21.950149Z","shell.execute_reply":"2023-08-25T17:25:21.948748Z","shell.execute_reply.started":"2023-08-25T17:25:21.939478Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["training complete. file saved to data.pth\n"]}],"source":["data = {\n","\"model_state\": model.state_dict(),\n","\"input_size\": input_size,\n","\"hidden_size\": hidden_size,\n","\"output_size\": output_size,\n","\"all_words\": all_words,\n","\"tags\": tags\n","}\n","\n","FILE = \"data.pth\"\n","torch.save(data, FILE)\n","\n","print(f'training complete. file saved to {FILE}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-08-25T17:25:21.953067Z","iopub.status.busy":"2023-08-25T17:25:21.952228Z","iopub.status.idle":"2023-08-25T17:29:03.764172Z","shell.execute_reply":"2023-08-25T17:29:03.762527Z","shell.execute_reply.started":"2023-08-25T17:25:21.952999Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Let's chat! (type 'quit' to exit)\n"]},{"name":"stdout","output_type":"stream","text":["You:  hello\n"]},{"name":"stdout","output_type":"stream","text":["Medical ChatBot: Hi there. What brings you here today?\n"]},{"name":"stdout","output_type":"stream","text":["You:  iam having an headache\n"]},{"name":"stdout","output_type":"stream","text":["Medical ChatBot: Not sure I understand that.\n"]},{"name":"stdout","output_type":"stream","text":["You:  I am feeling dizzy\n"]},{"name":"stdout","output_type":"stream","text":["Medical ChatBot: It'll all be okay. This feeling is only momentary.\n"]},{"name":"stdout","output_type":"stream","text":["You:  my stomach is aching\n"]},{"name":"stdout","output_type":"stream","text":["Medical ChatBot: Sorry, I didn't understand you.\n"]},{"name":"stdout","output_type":"stream","text":["You:  i have ache in my stomach\n"]},{"name":"stdout","output_type":"stream","text":["Medical ChatBot: That's no problem. I can see why you'd be stressed out about that. I can suggest you some tips to alleviate this issue. Would you like to learn more about that?\n"]},{"name":"stdout","output_type":"stream","text":["You:  yes\n"]},{"name":"stdout","output_type":"stream","text":["Medical ChatBot: Can you elaborate on that?\n"]},{"name":"stdout","output_type":"stream","text":["You:  no\n"]},{"name":"stdout","output_type":"stream","text":["Medical ChatBot: I'm listening. Please go on.\n"]},{"name":"stdout","output_type":"stream","text":["You:  i quit\n"]},{"name":"stdout","output_type":"stream","text":["Medical ChatBot: Not sure I understand that.\n"]},{"name":"stdout","output_type":"stream","text":["You:  quit\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","\n","\n","FILE = \"data.pth\"\n","data = torch.load(FILE)\n","\n","input_size = data[\"input_size\"]\n","hidden_size = data[\"hidden_size\"]\n","output_size = data[\"output_size\"]\n","all_words = data['all_words']\n","tags = data['tags']\n","model_state = data[\"model_state\"]\n","\n","model = NeuralNet(input_size, hidden_size, output_size).to(device)\n","model.load_state_dict(model_state)\n","model.eval()\n","\n","bot_name = \"Medical ChatBot\"\n","print(\"Let's chat! (type 'quit' to exit)\")\n","while True:\n","    # sentence = \"do you use credit cards?\"\n","    sentence = input(\"You: \")\n","    if sentence == \"quit\":\n","        break\n","\n","    sentence = tokenize(sentence)\n","    X = bag_of_words(sentence, all_words)\n","    X = X.reshape(1, X.shape[0])\n","    X = torch.from_numpy(X).to(device)\n","\n","    output = model(X)\n","    _, predicted = torch.max(output, dim=1)\n","\n","    tag = tags[predicted.item()]\n","\n","    probs = torch.softmax(output, dim=1)\n","    prob = probs[0][predicted.item()]\n","    if prob.item() > 0.75:\n","        for intent in intents['intents']:\n","            if tag == intent[\"tag\"]:\n","                print(f\"{bot_name}: {random.choice(intent['responses'])}\")\n","    else:\n","        print(f\"{bot_name}: I do not understand...\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
